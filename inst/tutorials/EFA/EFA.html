<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<meta name="progressive" content="true" />
<meta name="allow-skip" content="true" />

<title>Sitzung 2: Exploratorische Faktorenanalyse</title>

<p style="margin-bottom:90px">
  <img src="https://upload.wikimedia.org/wikipedia/de/thumb/f/f0/Goethe-Logo.svg/500px-Goethe-Logo.svg.png" style="position:absolute;top:10px;right:10px;" width="150" height="81.6" />
</p>

<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>

<!-- taken from https://github.com/rstudio/rmarkdown/blob/67b7f5fc779e4cfdfd0f021d3d7745b6b6e17149/inst/rmd/h/default.html#L296-L362 -->
<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>
<!-- end tabsets -->



</head>

<body>



<div class="pageContent band">
<div class="bandContent page">

<div class="topics">

<p><em>Forschungsmethoden und Evaluation II, PsyMSc 1, Sommersemester 2020 — EFA</em></p>
<div id="section-einleitung-zur-exploratorischen-faktorenanalyse-efa" class="section level2">
<h2>Einleitung zur exploratorischen Faktorenanalyse (EFA)</h2>
<p>Forscher der Psychologie oder anderer Natur-, Sozial- und Geisteswissenschaften interessieren sich häufig dafür, dass sich Daten runterbrechen lassen auf einige wenige entscheidende Faktoren, welche ein theoretisches Erklärungsmodell für die Variation in einem Datensatz liefern. Die Annahme ist hierbei, dass die beobachtbaren Messungen eine Linearkombination (also eine Summe) aus einem systematischen (wahren) und einem unsystematischen (Fehler-) Anteil bilden. Die dahinterliegenden Faktoren sind nicht messbare (latente) Variablen, auf welche, unter gewissen Annahmen, nur anhand der Kovariation zwischen den beobachtbaren Item geschlossen werden kann. Durch diese Zusammenhänge zwischen den Messungen können schließlich Hypothesen für die latenten Varibalen untersucht werden. Ein theoriegenerierendes Verfahren, das hierzu häufig verwendet wird, ist die <strong>exploratorische Faktorenanalyse (EFA)</strong>. Wir wollen dieses Verfahren zur Auswertung von Beziehungen zwischen Variablen in <code>R</code> näher kennenlernen.</p>
<p>Bevor wir mit den Analysen beginnen können, laden wir zunächst alle Pakete, welche wir im Folgenden benötigen werden.</p>
<pre class="r"><code>library(corrplot) # Korrelationsmatrix grafisch darstellen
library(psych) # EFA durchführen
library(GPArotation) # EFA Lösung rotieren</code></pre>
</div>
<div id="section-datensatz" class="section level2">
<h2>Datensatz</h2>
<p>Wir wollen uns die Faktorenstruktur der <em>Big-5</em> eines entsprechenden Fragebogens ansehen. Der Originaldatensatz ist ein Onlinedatensatz, wird seit 2012 erfasst und ist <a href="https://openpsychometrics.org/_rawdata/">hier</a> als <em>.zip</em> downloadbar. Bisher haben über <strong>19700</strong> Probanden aus der ganzen Welt teilgenommen. Zu jeder der fünf Facetten gibt es 10 Fragen. Der Fragebogen ist <a href="http://personality-testing.info/tests/BIG5.php">hier</a> einzusehen. Um das Ganze etwas übersichtlicher zu gestalten, betrachten wir einen gekürzten Datensatz. Im Datensatz <em>Big5.rda</em> befinden sich 15 Items aus dem Big-5 Persönlichkeits Fragebogen. Hier werden von diesen 10 Items jeweils die ersten drei verwendet. Der Itemwortlaut der verwendeten Items ist</p>
<table class="gmisc_table" style="border-collapse: collapse; margin-top: 1em; margin-bottom: 1em;">
<thead>
<tr>
<td colspan="2" style="text-align: left;">
Itemwortlaut
</td>
</tr>
<tr>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: center;">
Item Nr.
</th>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: center;">
Item
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">
E1
</td>
<td style="text-align: left;">
I am the life of the party.
</td>
</tr>
<tr>
<td style="text-align: center;">
E2
</td>
<td style="text-align: left;">
I don’t talk a lot.
</td>
</tr>
<tr>
<td style="text-align: center;">
E3
</td>
<td style="text-align: left;">
I feel comfortable around people.
</td>
</tr>
<tr>
<td style="text-align: center;">
N1
</td>
<td style="text-align: left;">
I get stressed out easily.
</td>
</tr>
<tr>
<td style="text-align: center;">
N2
</td>
<td style="text-align: left;">
I am relaxed most of the time.
</td>
</tr>
<tr>
<td style="text-align: center;">
N3
</td>
<td style="text-align: left;">
I worry about things.
</td>
</tr>
<tr>
<td style="text-align: center;">
A1
</td>
<td style="text-align: left;">
I feel little concern for others.
</td>
</tr>
<tr>
<td style="text-align: center;">
A2
</td>
<td style="text-align: left;">
I am interested in people.
</td>
</tr>
<tr>
<td style="text-align: center;">
A3
</td>
<td style="text-align: left;">
I insult people.
</td>
</tr>
<tr>
<td style="text-align: center;">
C1
</td>
<td style="text-align: left;">
I am always prepared.
</td>
</tr>
<tr>
<td style="text-align: center;">
C2
</td>
<td style="text-align: left;">
I leave my belongings around.
</td>
</tr>
<tr>
<td style="text-align: center;">
C3
</td>
<td style="text-align: left;">
I pay attention to details.
</td>
</tr>
<tr>
<td style="text-align: center;">
O1
</td>
<td style="text-align: left;">
I have a rich vocabulary.
</td>
</tr>
<tr>
<td style="text-align: center;">
O2
</td>
<td style="text-align: left;">
I have difficulty understanding abstract ideas.
</td>
</tr>
<tr>
<td style="border-bottom: 2px solid grey; text-align: center;">
O3
</td>
<td style="border-bottom: 2px solid grey; text-align: left;">
I have a vivid imagination.
</td>
</tr>
</tbody>
</table>
<p>Die Kürzung des vollen Datensatzes lässt sich hier nachvollziehen:</p>
<pre class="r"><code>data_full &lt;- read.table(&quot;BIG5/data.csv&quot;, header = T, sep = &quot;\t&quot;) # nach entpacken des .zip liegen die Daten in einem Ordner namens Big5

### Entferne leere Zeilen und Zeilen mit Missings aus dem Datensatz
ind &lt;- apply(data_full, 1, FUN = function(x) any(is.na(x))) # erzeuge eine Variable, welche TRUE ist, wenn mindestens ein Eintrag pro Zeile fehlt und ansonsten FALSE anzeigt
data_full &lt;- data_full[!ind, ] # Wähle nur diejenigen Zeilen, in denen unsere Indikatorvariable &quot;ind&quot; NICHT TRUE anzeigt, also wo alle Einträge vorhanden sind
# !ind (Ausrufezeichen vor ind) negiert die Einträge in ind (Prüfe bspw. !FALSE == TRUE, nicht false ist gleich true)

### Shorten Data Set
Big5 &lt;- data_full[, c(2:4,7,7+rep(1:3,5)+sort(rep(seq(0,40,10),3)))]
 # Verwende nur 3 Items pro Skala plus einige demografische Items
Big5 &lt;- data.frame(Big5) # Schreibe Datensatz als data.frame
save(list = c(&quot;Big5&quot;), file = &quot;Big5.rda&quot;)
# Speichere gekürzten Datensatz in .rda file (dem R-internen Datenformat)
## --&gt; Das ist auch der Datensatz, den wir weiter verwenden werden!</code></pre>
<p>Zusätzlich zu den Persönlichkeitsitems wurden demografische Daten, die mögliche Unterschiede zwischen Personen beschreiben, erfasst.</p>
<pre class="r"><code># Datensatz laden 
load(&quot;Big5.rda&quot;) # shortend Big 5 Questionnaire Data Set
head(Big5, n = 10) # gebe die ersten 10 Zeilen aus</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["age"],"name":[1],"type":["int"],"align":["right"]},{"label":["engnat"],"name":[2],"type":["int"],"align":["right"]},{"label":["gender"],"name":[3],"type":["int"],"align":["right"]},{"label":["country"],"name":[4],"type":["fctr"],"align":["left"]},{"label":["E1"],"name":[5],"type":["int"],"align":["right"]},{"label":["E2"],"name":[6],"type":["int"],"align":["right"]},{"label":["E3"],"name":[7],"type":["int"],"align":["right"]},{"label":["N1"],"name":[8],"type":["int"],"align":["right"]},{"label":["N2"],"name":[9],"type":["int"],"align":["right"]},{"label":["N3"],"name":[10],"type":["int"],"align":["right"]},{"label":["A1"],"name":[11],"type":["int"],"align":["right"]},{"label":["A2"],"name":[12],"type":["int"],"align":["right"]},{"label":["A3"],"name":[13],"type":["int"],"align":["right"]},{"label":["C1"],"name":[14],"type":["int"],"align":["right"]},{"label":["C2"],"name":[15],"type":["int"],"align":["right"]},{"label":["C3"],"name":[16],"type":["int"],"align":["right"]},{"label":["O1"],"name":[17],"type":["int"],"align":["right"]},{"label":["O2"],"name":[18],"type":["int"],"align":["right"]},{"label":["O3"],"name":[19],"type":["int"],"align":["right"]}],"data":[{"1":"53","2":"1","3":"1","4":"US","5":"4","6":"2","7":"5","8":"1","9":"5","10":"2","11":"1","12":"5","13":"1","14":"4","15":"1","16":"5","17":"4","18":"1","19":"3","_rn_":"1"},{"1":"46","2":"1","3":"2","4":"US","5":"2","6":"2","7":"3","8":"2","9":"3","10":"4","11":"1","12":"3","13":"3","14":"4","15":"1","16":"3","17":"3","18":"3","19":"3","_rn_":"2"},{"1":"14","2":"2","3":"2","4":"PK","5":"5","6":"1","7":"1","8":"5","9":"1","10":"5","11":"5","12":"1","13":"5","14":"4","15":"1","16":"5","17":"4","18":"5","19":"5","_rn_":"3"},{"1":"19","2":"2","3":"2","4":"RO","5":"2","6":"5","7":"2","8":"5","9":"4","10":"4","11":"2","12":"5","13":"4","14":"3","15":"3","16":"4","17":"4","18":"3","19":"5","_rn_":"4"},{"1":"25","2":"2","3":"2","4":"US","5":"3","6":"1","7":"3","8":"3","9":"3","10":"3","11":"5","12":"5","13":"3","14":"3","15":"1","16":"5","17":"3","18":"1","19":"1","_rn_":"5"},{"1":"31","2":"1","3":"2","4":"US","5":"1","6":"5","7":"2","8":"1","9":"5","10":"4","11":"2","12":"2","13":"3","14":"2","15":"5","16":"4","17":"4","18":"2","19":"1","_rn_":"6"},{"1":"20","2":"1","3":"2","4":"US","5":"5","6":"1","7":"5","8":"2","9":"4","10":"2","11":"5","12":"5","13":"1","14":"2","15":"4","16":"3","17":"3","18":"1","19":"5","_rn_":"7"},{"1":"23","2":"2","3":"1","4":"IN","5":"4","6":"3","7":"5","8":"1","9":"4","10":"4","11":"2","12":"5","13":"1","14":"4","15":"2","16":"5","17":"3","18":"1","19":"5","_rn_":"8"},{"1":"39","2":"1","3":"2","4":"US","5":"3","6":"1","7":"5","8":"2","9":"4","10":"5","11":"1","12":"5","13":"1","14":"4","15":"3","16":"5","17":"3","18":"3","19":"5","_rn_":"9"},{"1":"18","2":"1","3":"2","4":"US","5":"1","6":"4","7":"2","8":"5","9":"2","10":"5","11":"2","12":"3","13":"1","14":"5","15":"2","16":"4","17":"4","18":"2","19":"5","_rn_":"10"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Wir sehen, dass in den ersten 4 Spalten die demografischen Daten wie etwa <em>Alter (“age”)</em>, <em>Englisch als Muttersprache (“engant”, 1=yes, 2=no, 0=missed)</em>, <em>Geschlecht (“gender”, 1=Male, 2=Female, 3=Other, 0=missed)</em> und <em>Herkunftsland (“country”, ISO-kodiert, bspw. “DE” = Deutschland, “FR” = Frankreich, “EM” = Vereinigte Arabische Emirate, “US” = Vereinigten Staaten von Amerika)</em> eingetragen wurden. In den darauf folgenden Spalten sind die Items der Extraversion (engl. <em>extraversion</em>, Items:<em>E1</em>, <em>E2</em>, <em>E3</em>), des Neurotizismus (engl. <em>neuroticism</em>, Items: <em>N1</em>, <em>N2</em>, <em>N3</em>), der Verträglichkeit (engl. <em>agreeableness</em>, Items: <em>A1</em>, <em>A2</em>, <em>A3</em>), der Gewissenhaftigkeit (engl. <em>conscientiousness</em>, Items: <em>C1</em>, <em>C2</em>, <em>C3</em>) und der Offenheit für Erfahrungen (engl. <em>openness</em>, Items: <em>O1</em>, <em>O2</em>, <em>O3</em>) eingetragen. Beispielsweise ist die erste Person des Datensatzes ein 53-jähriger Mann, der Englisch als Muttersprache spricht und in den USA lebt.</p>
<p>Da wir uns in der Praxis nur sehr selten in der glücklichen Lage befinden, einen solch riesigen Datensatz zu haben, wollen wir uns innerhalb des Datensatzes auf Subgruppen beschränken: wir wollen uns zunächst nur Daten von Personen aus <em>Frankreich</em> ansehen. Dazu wählen wir nur diejenigen Spalten aus, in denen <code>country == &quot;FR&quot;</code> gilt. Das erreichen wir wie folgt:</p>
<pre class="r"><code>data_France &lt;- Big5[Big5$country == &quot;FR&quot;, ]
dim(data_France)</code></pre>
<pre><code>## [1] 129  19</code></pre>
<p>Mit <code>Big5$country</code> haben wir Zugriff auf die “Country”-Spalte im Datensatz und können mit <code>== FR</code> prüfen, an welchen Stellen hier “FR” steht, also Personen, die in Frankreich leben. <code>dim</code> gibt die Dimensionen des Datensatzes wieder. <code>dim_France</code> enthält also 129 Zeilen (also Probanden, die in Frankreich leben) und 19 Spalten (also Variablen). Für die weiteren Analysen brauchen wir die demografischen Variablen in dem Datensatz der in Frankreich lebenden Teilnehmer nicht mehr. Aus diesem Grund speichern wir den Datensatz noch einmal ohne die ersten 4 Spalten ab.</p>
<pre class="r"><code>dataFR &lt;- data_France[, -c(1:4)] # entferne demografische Daten und speichere als &quot;dataFR&quot;

#### Visualisierte Korrelationsmatrix in dataFR
corrplot(corr = cor(dataFR), # Korrelationsmatrix (Datengrundlage)
         method = &quot;color&quot;, # Zeichne die Ausprägung der Korrelation farblich kodiert
         addCoef.col = &quot;black&quot;, # schreibe die Korrelationskoeffizienten in schwarz in die Grafik
         number.cex = 0.7) # Stelle die Schriftgröße der Koeffizienten ein</code></pre>
<p><img src="EFA_files/figure-html/unnamed-chunk-5-1.png" width="624" /></p>
<p>Auf den ersten Blick scheinen die Items der gleichen Skala stärker (betragsmäßig höher) miteinander zu korrelieren. Allerdings sind hier sehr viele Korrelationen abgetragen. Wir wollen uns zunächst nur auf Extraversion und Neurotizismus beschränken.</p>
<pre class="r"><code>dataFR2 &lt;- dataFR[,1:6] # Zunächst wählen wir 6 Items
head(dataFR2)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["E1"],"name":[1],"type":["int"],"align":["right"]},{"label":["E2"],"name":[2],"type":["int"],"align":["right"]},{"label":["E3"],"name":[3],"type":["int"],"align":["right"]},{"label":["N1"],"name":[4],"type":["int"],"align":["right"]},{"label":["N2"],"name":[5],"type":["int"],"align":["right"]},{"label":["N3"],"name":[6],"type":["int"],"align":["right"]}],"data":[{"1":"1","2":"3","3":"2","4":"4","5":"2","6":"3","_rn_":"17"},{"1":"3","2":"3","3":"3","4":"4","5":"3","6":"4","_rn_":"398"},{"1":"1","2":"5","3":"2","4":"4","5":"4","6":"5","_rn_":"488"},{"1":"1","2":"2","3":"1","4":"4","5":"1","6":"5","_rn_":"545"},{"1":"1","2":"4","3":"1","4":"5","5":"1","6":"5","_rn_":"551"},{"1":"1","2":"4","3":"2","4":"5","5":"1","6":"5","_rn_":"656"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code># Visualisierte Korrelationsmatrix
corrplot(corr = cor(dataFR2), # Korrelationsmatrix (Datengrundlage)
         method = &quot;color&quot;, # Zeichne die Ausprägung der Korrelation farblich kodiert
         addCoef.col = &quot;black&quot;, # schreibe die Korrelationskoeffizienten in schwarz in die Grafik
         number.cex = 1) # Stelle die Schriftgröße der Koeffizienten ein</code></pre>
<p><img src="EFA_files/figure-html/unnamed-chunk-6-1.png" width="624" /></p>
<p>Hier ist nun deutlich zu sehen, dass die Extraversionsitems und die Neurotizismusitems untereinander jeweils stärker zusammenhängen als zwischen den Konstrukten. Dennoch ist der Grafik zu entnehmen, dass die beiden Konstrukte nicht unabhängig voneinander sind (es gibt Beziehungen zwischen Items der beiden Konstrukte).</p>
</div>
<div id="section-ziel-efa" class="section level2">
<h2>Ziel: EFA</h2>
<p>Unser Ziel ist es, mit den gegebenen Items eine exploratorische Faktorenanalyse durchzuführen. Wir wollen hierbei die Anzahl der Faktoren mittels einer Parallelanalyse bestimmen und anschließend dieses Modell mit dem <span class="math inline">\(\chi^2\)</span>-Test (<em>Likelihood-Quotiententest/ Likelihood-Differenzentest</em>/ <span class="math inline">\(\chi^2\)</span>-<em>Differenzentest</em>) gegen konkurrierende Modelle vergleichen. Hierbei wollen wir die oblique rotierte und die orthogonal rotierte Lösung vergleichen und hinsichtlich unserer Daten interpretieren. Das Modell, was wir an unsere Daten anpassen wollen, sieht für 6 Variablen (<span class="math inline">\(V_1,\dots,V_6\)</span>) im Allgemeinen erst einmal so aus:</p>
<p><img src="/Users/JulienMac/PowerFolders/Promotion/Lehre/2020%20Sommersemester/F&E%20II/PC-U%CC%88bung/EFA/EFA_Modell.png" width=80%"/></p>
<p>Auf unseren Datensatz angepasst, wollen wir folgendes Modell anpassen.</p>
<p><img src="/Users/JulienMac/PowerFolders/Promotion/Lehre/2020%20Sommersemester/F&E%20II/PC-U%CC%88bung/EFA/specific_model.png" width=80%"/></p>
<p>Natürlich erwarten wir, dass insgesamt 2 Faktoren die Daten am besten beschreiben und dass die konstruktkongruenten Items jeweils auf dem gleichen Faktor am stärksten laden. Aber stützen die Daten diese Hypothese?</p>
<p>Wir wollen im Folgenden</p>
<ul>
<li>eine Parallelanalyse durchführen, um in Erfahrung zu bringen, wie viele Faktoren sinnvoll zu den Daten passen</li>
<li>eine Hauptachsenanalyse mit orthogonaler und obliquer Rotation durchführen</li>
<li>eine exploratorische Maximum-Likelihood-Faktorenanalyse durchführen und die Passung zu den Daten untersuchen</li>
<li>im Rahmen der exploratorischen Maximum-Likelihood-Faktorenanalyse die Passung zu den Daten im Vergleich zu konkurrierenden Modellen untersuchen.</li>
</ul>
<div id="section-parallelanalyse-und-auswahl-an-faktoren" class="section level3">
<h3>Parallelanalyse und Auswahl an Faktoren</h3>
<p>Zur Auswahl der Anzahl an Faktoren in der EFA kann auf die Eigenwerte zurückgegriffen werden. Diese Eigenwerte entstehen beispielsweise durch Lösen des Eigenwerteproblems und entsprechen den Varianzen der Faktoren. Hier gilt es nur solche Faktoren zu wählen, die auch große Varianzen haben. Die Parallelanalyse hatten wir im Zusammenhang mit der Hauptkomponentenanalyse (<em>PCA, principal component analysis</em>) kennengelernt. Hier werden vielfach (z.B. 1000 Mal) unabhängige Daten in dem gleichen Format des ursprünglichen Datensatzes gezogen und eine PCA oder EFA durchgeführt. Die entstehenden Eigenwerte werden der Größe nach erfasst und dann über die Wiederholungen gemittelt. So entsteht ein auf die Stichprobe und Anzahl der Variablen genormter, zufälliger Eigenwerteverlauf. Sind Eigenwerte der tatsächlich beobachteten Daten größer als die der Parallelanalyse, so spricht dies für eine/n bedeutsame/n Komponente/Faktor. Weitere Kriterien zur Auswahl von zu extrahierenden Faktoren im Rahmen der PCA waren das <em>Eigenwerte-größer-1 Kriterium (Kaiser-Guttman-Kriterium)</em> sowie der <em>Scree-Test (Ellbow-Criterion, Knick im Eigenwerteverlauf)</em>. Weitere Informationen zur EFA sowie zu Wiederholungen der PCA und der Auswahlkriterien können beispielsweise in Eid, Gollwitzer und Schmitt (2017) in Kapitel 25 (Seite 919 und folgend) nachgelesen werden.</p>
<p>Der wesentliche Unterschied zwischen einer EFA und einer PCA ist, dass in der EFA angenommen wird, dass die beobachteten Variablen systematische (wahre) und unsystematische (Fehler-) Anteile enthalten. Es wird somit ein Erklärungsmodell, welches die Variation zwischen den Variablen erzeugt, postuliert. Bei der PCA werden die beobachteten Variablen als messfehlerfrei angenommen. Eine wichtige Folge aus der Modellierung der Fehler ist, dass in der Regel die Faktorladungen bei der PCA höher ausfallen als bei der EFA. Dies liegt daran, dass bei der PCA die Variablen mit ihren eigenen Messfehlern, aus welchen auch die Hauptkomponenten unter anderem zusammengesetzt sind, korrelieren. Die Faktorladungen/Komponentenladungen stehen hierbei (im orthogonalen Fall) für die Korrelation zwischen Item und Faktor/Komponente. Wird eine ML-EFA an die Daten angepasst, so wird zusätzlich noch ein Erklärungsmodell basierend auf Verteilungsannahmen (multivariate Normalverteilung der Items, Faktoren und Fehler) herangezogen. Bei der PCA sind die Hauptkomponenten lediglich Linearkombinationen aus den beobachteten Variablen ohne jegliche Verteilungsannahmen (die Hauptkomponenten bestehen aus gewichteten Summen der beobachteten Variablen).</p>
<p>Mit Hilfe des <code>fa.parallel</code> Befehls aus dem <code>psych</code>-Paket, welchen wir im Rahmen der PCA bereits kennengelernt hatten, lässt sich ganz einfach der Eigenwerteverlauf inklusive Parallelanalyse grafisch darstellen.</p>
<pre class="r"><code>fa.parallel(dataFR2)</code></pre>
<p><img src="EFA_files/figure-html/unnamed-chunk-7-1.png" width="624" /></p>
<pre><code>## Parallel analysis suggests that the number of factors =  2  and the number of components =  2</code></pre>
<p>Ohne weitere Einstellungen wird der Eigenwerteverlauf der PCA und der EFA ausgegeben. Deutlich zu sehen ist, dass die Eigenwerte der PCA größer ausfallen als die der EFA. Dies liegt erneut daran, dass die Faktoren der EFA lediglich die systematischen Anteile der Variablen enthalten, während die Komponenten der PCA Kompositionen sind - also Zusammensetzungen aus den Variablen; inklusive der Messfehler.</p>
<pre class="r"><code>fa.parallel(dataFR2, fa = &quot;fa&quot;)</code></pre>
<p><img src="EFA_files/figure-html/unnamed-chunk-8-1.png" width="624" /></p>
<pre><code>## Parallel analysis suggests that the number of factors =  2  and the number of components =  NA</code></pre>
<p>Die Grafik zeigt drei Eigenwerteverläufe. <em>FA Actual Data</em> ist der Eigenwerteverlauf unseres Datensatzes. <em>FA Simulated Data</em> ist der Eigenwerteverlauf basierend auf den 1000 simulierten Datensätzen. <em>FA Resampled Data</em> ist der Eigenwerteverlauf von Datensätzen, der durch <em>Resampling</em>, also neues Verteilen unseres Datensatzes entsteht. Da beim Resampling die Systematiken unseres Datensatzes verloren gehen, sollte das Resampling einen ähnlichen Eigenwerteverlauf wie die unabhängig gezogenen Datensätze zeigen.</p>
<p>Der Parallelanalyse der EFA ist zu entnehmen, dass voraussichtlich 2 Faktoren genügen, um die Variation im Datensatz zu erklären. Auch die Parallelanalyse der PCA (Grafik zuvor) lässt dies vermuten. Des Weiteren sprechen beide Scree-Tests für einen Knick um den 3. Faktor/die 3. Komponente, was auch für eine Dimensionalität von 2 spricht. Zu guter Letzt zeigt auch das Kaiser-Guttman-Kriterium kein anderes Ergebnis. Allerdings ist dieses Kriterium nur sinnvoll auf den Eigenwerteverlauf der PCA anwendbar, weswegen wir es auch nur im Bezug auf den PCA-Eigenwerteverlauf interpretieren.</p>
</div>
<div id="section-orthogonale-und-oblique-hauptachsenanalyse" class="section level3">
<h3>Orthogonale und oblique Hauptachsenanalyse</h3>
<p>Da unsere Auswahlkriterien einstimmig für 2 Faktoren sprechen und dies auch unsere Hypothese war, modellieren wir zunächst eine orthogonale Hauptachsenanalyse. Dazu nutzen wir den <code>fa</code> (Factor Analysis) Befehl des <code>psych</code> Paketes. Mit Hilfe der Argumente <code>nfactors</code> und <code>rotate</code> lässt sich die Anzahl an Faktoren sowie die Rotation auswählen. Wir wollen hier orthogonal varianzmaximierend (also <em>varimax</em>) rotieren.</p>
<pre class="r"><code>fa(dataFR2, nfactors = 2, rotate = &quot;varimax&quot;)</code></pre>
<pre><code>## Factor Analysis using method =  minres
## Call: fa(r = dataFR2, nfactors = 2, rotate = &quot;varimax&quot;)
## Standardized loadings (pattern matrix) based upon correlation matrix
##      MR1   MR2   h2   u2 com
## E1  0.69 -0.06 0.48 0.52 1.0
## E2 -0.65  0.00 0.42 0.58 1.0
## E3  0.82 -0.19 0.70 0.30 1.1
## N1 -0.01  0.84 0.70 0.30 1.0
## N2  0.10 -0.58 0.35 0.65 1.1
## N3 -0.05  0.59 0.34 0.66 1.0
## 
##                        MR1  MR2
## SS loadings           1.58 1.42
## Proportion Var        0.26 0.24
## Cumulative Var        0.26 0.50
## Proportion Explained  0.53 0.47
## Cumulative Proportion 0.53 1.00
## 
## Mean item complexity =  1
## Test of the hypothesis that 2 factors are sufficient.
## 
## The degrees of freedom for the null model are  15  and the objective function was  1.47 with Chi Square of  183.82
## The degrees of freedom for the model are 4  and the objective function was  0.07 
## 
## The root mean square of the residuals (RMSR) is  0.04 
## The df corrected root mean square of the residuals is  0.07 
## 
## The harmonic number of observations is  129 with the empirical chi square  4.98  with prob &lt;  0.29 
## The total number of observations was  129  with Likelihood Chi Square =  9.06  with prob &lt;  0.06 
## 
## Tucker Lewis Index of factoring reliability =  0.886
## RMSEA index =  0.102  and the 90 % confidence intervals are  0 0.187
## BIC =  -10.38
## Fit based upon off diagonal values = 0.99
## Measures of factor score adequacy             
##                                                    MR1  MR2
## Correlation of (regression) scores with factors   0.89 0.88
## Multiple R square of scores with factors          0.79 0.77
## Minimum correlation of possible factor scores     0.58 0.55</code></pre>
<p>Im Output ganz oben erkennen wir die Schätzmethode (hier: <code>minres</code>, also Minimierung der Residuen). Aus diesem Grund heißen die Faktoren in diesem Output auch <em>MR1</em> und <em>MR2</em>; für <em>Minimale-Residuen-Faktor 1</em> und <em>2</em>. Die Faktorladungen zu den zugehörigen Faktoren sind unter <code>Standardized loadings (pattern matrix) based upon correlation matrix</code> zu sehen. <code>h2</code> steht für die Kommunalität (<span class="math inline">\(h^2\)</span>), also den Anteil an systematischer Variation, die auf die 2 Faktoren zurückzuführen ist (diese kann ähnlich der Reliabilität interpretiert werden). <code>u2</code> ist die “uniqueness” (<span class="math inline">\(u^2\)</span>), also der unerklärte Anteil. Offensichtlich gilt <span class="math inline">\(u^2 = 1-h^2\)</span> oder <span class="math inline">\(h^2 + u^2 = 1\)</span>. Unter den Faktorladungen erhalten wir Informationen über die Faktoren. <code>SS loadings</code> steht für “Sum of Squares loadings”, also die Quadratsumme der Faktorladungen. Diese ist gleich dem Eigenwert: <span class="math inline">\(\theta_j = \Sigma_{i=1}^p\lambda_{ij}^2 = \lambda_{1j}^2+\dots+\lambda_{pj}^2\)</span> (Spaltenquadratsumme der Faktorladungen), mit <span class="math inline">\(p=\)</span> Anzahl an Variablen (hier <span class="math inline">\(p=6\)</span>). <code>Proportion Var</code> betitelt den Anteil der Variation, der durch die jeweiligen Faktoren erklärt werden kann. <code>Cumulative Var</code> kummuliert, also summiert, diese Anteile auf. <code>Proportion Explained</code> setzt die Variation, die durch die Faktoren erklärt wird, in Relation zur gesamten erklärten Varianz (d.h. hier summiert sich die erklärte Varianz immer zu 1, während die sich proportionale Varianz nur zu 1 aufsummiert, wenn die gesamte Variation im Datensatz auf die beiden Variablen zurückzuführen ist). <code>Cumulative Proportion</code> beschreibt das gleiche wie <code>Cumulative Var</code>, nur wird sich hier auf die <code>Proportion Explained</code> bezogen. Bei der Interpretation dieser Kennwerte ist jedoch zu bedenken, dass bei der EFA angenommen wird, dass die beobachteten Variablen Messfehler enthalten (also die Reliabilität nicht als 1 angenommen werden kann). Folglich ist die Kommunalität <span class="math inline">\(h^2\)</span> nicht 1 und wir können nicht unbedingt davon ausgehen, dass die Faktoren die gesamte Variation der Daten erklären.</p>
<p>Da durch diesen Befehl sehr viele Informationen ausgegeben werden, speichern wir uns diese Analyse als ein Objekt ab, welchem wir dann gezielt Informationen mit Hilfe von <code>...$...</code> entlocken können. Welche Argumente entlockt werden können, kann beispielsweise mit <code>names</code> herausgefunden werden.</p>
<pre class="r"><code>two_factor &lt;- fa(dataFR2, nfactors = 2, rotate = &quot;varimax&quot;)
names(two_factor)</code></pre>
<pre><code>##  [1] &quot;residual&quot;      &quot;dof&quot;           &quot;chi&quot;           &quot;nh&quot;           
##  [5] &quot;rms&quot;           &quot;EPVAL&quot;         &quot;crms&quot;          &quot;EBIC&quot;         
##  [9] &quot;ESABIC&quot;        &quot;fit&quot;           &quot;fit.off&quot;       &quot;sd&quot;           
## [13] &quot;factors&quot;       &quot;complexity&quot;    &quot;n.obs&quot;         &quot;objective&quot;    
## [17] &quot;criteria&quot;      &quot;STATISTIC&quot;     &quot;PVAL&quot;          &quot;Call&quot;         
## [21] &quot;null.model&quot;    &quot;null.dof&quot;      &quot;null.chisq&quot;    &quot;TLI&quot;          
## [25] &quot;RMSEA&quot;         &quot;BIC&quot;           &quot;SABIC&quot;         &quot;r.scores&quot;     
## [29] &quot;R2&quot;            &quot;valid&quot;         &quot;score.cor&quot;     &quot;weights&quot;      
## [33] &quot;rotation&quot;      &quot;communality&quot;   &quot;communalities&quot; &quot;uniquenesses&quot; 
## [37] &quot;values&quot;        &quot;e.values&quot;      &quot;loadings&quot;      &quot;model&quot;        
## [41] &quot;fm&quot;            &quot;rot.mat&quot;       &quot;Structure&quot;     &quot;method&quot;       
## [45] &quot;scores&quot;        &quot;R2.scores&quot;     &quot;r&quot;             &quot;np.obs&quot;       
## [49] &quot;fn&quot;            &quot;Vaccounted&quot;</code></pre>
<p>Beispielsweise erhalten wir mit <code>$loadings</code> die Faktorladungsmatrix sowie Informationen über die Eigenwerte.</p>
<pre class="r"><code>two_factor$loadings</code></pre>
<pre><code>## 
## Loadings:
##    MR1    MR2   
## E1  0.692       
## E2 -0.646       
## E3  0.819 -0.186
## N1         0.837
## N2        -0.580
## N3         0.585
## 
##                  MR1   MR2
## SS loadings    1.578 1.419
## Proportion Var 0.263 0.236
## Cumulative Var 0.263 0.499</code></pre>
<p>Hier ist relativ deutlich die Zuordnung zu den jeweiligen Faktoren zu sehen. Faktor 1 (<em>MR1</em>) entspräche demnach der Extraversion, während der zweite Faktor (<em>MR2</em>) dem Neurotizismus entspräche. Da wir nicht davon ausgehen können, dass die Faktoren unkorreliert sind, wollen wir die gleiche Analyse nun für <em>oblique</em> (“oblimin” in <code>R</code>) rotierte Faktoren durchführen.</p>
<pre class="r"><code>two_factor_oblimin &lt;- fa(dataFR2, nfactors = 2, rotate = &quot;oblimin&quot;)
two_factor_oblimin</code></pre>
<pre><code>## Factor Analysis using method =  minres
## Call: fa(r = dataFR2, nfactors = 2, rotate = &quot;oblimin&quot;)
## Standardized loadings (pattern matrix) based upon correlation matrix
##      MR1   MR2   h2   u2 com
## E1  0.70  0.04 0.48 0.52   1
## E2 -0.66 -0.09 0.42 0.58   1
## E3  0.82 -0.07 0.70 0.30   1
## N1  0.03  0.84 0.70 0.30   1
## N2  0.07 -0.57 0.35 0.65   1
## N3 -0.02  0.58 0.34 0.66   1
## 
##                        MR1  MR2
## SS loadings           1.61 1.39
## Proportion Var        0.27 0.23
## Cumulative Var        0.27 0.50
## Proportion Explained  0.54 0.46
## Cumulative Proportion 0.54 1.00
## 
##  With factor correlations of 
##       MR1   MR2
## MR1  1.00 -0.19
## MR2 -0.19  1.00
## 
## Mean item complexity =  1
## Test of the hypothesis that 2 factors are sufficient.
## 
## The degrees of freedom for the null model are  15  and the objective function was  1.47 with Chi Square of  183.82
## The degrees of freedom for the model are 4  and the objective function was  0.07 
## 
## The root mean square of the residuals (RMSR) is  0.04 
## The df corrected root mean square of the residuals is  0.07 
## 
## The harmonic number of observations is  129 with the empirical chi square  4.98  with prob &lt;  0.29 
## The total number of observations was  129  with Likelihood Chi Square =  9.06  with prob &lt;  0.06 
## 
## Tucker Lewis Index of factoring reliability =  0.886
## RMSEA index =  0.102  and the 90 % confidence intervals are  0 0.187
## BIC =  -10.38
## Fit based upon off diagonal values = 0.99
## Measures of factor score adequacy             
##                                                   MR1  MR2
## Correlation of (regression) scores with factors   0.9 0.88
## Multiple R square of scores with factors          0.8 0.78
## Minimum correlation of possible factor scores     0.6 0.55</code></pre>
<p>Die einzig wirklich neue Information können wir unter <code>With factor correlations of</code> ablesen: die Korrelation zwischen den Faktoren. Durch die andere Rotation ist zu sehen, dass sich die Kommunalitäten nicht ändern. Wir können also nicht mehr Variation im Datensatz erklären. Die Varianz wird nur umverteilt, wie den veränderten Eigenwerten neben <code>SS loadings</code> zu entnehmen ist. Hier hat der erste Faktor einen etwas größeren Eigenwert als im orthogonalen Fall (entsprechend ist der 2. Eigenwert kleiner, da nicht mehr Variation erklärt wird).</p>
<pre class="r"><code>two_factor_oblimin$loadings # Ladungsmatrix</code></pre>
<pre><code>## 
## Loadings:
##    MR1    MR2   
## E1  0.701       
## E2 -0.656       
## E3  0.823       
## N1         0.842
## N2        -0.571
## N3         0.583
## 
##                  MR1   MR2
## SS loadings    1.606 1.389
## Proportion Var 0.268 0.232
## Cumulative Var 0.268 0.499</code></pre>
<pre class="r"><code>two_factor_oblimin$Phi # Korrelationsmatrix der Faktoren</code></pre>
<pre><code>##            MR1        MR2
## MR1  1.0000000 -0.1852246
## MR2 -0.1852246  1.0000000</code></pre>
<p>Der Ladungsmatrix ist auch zu entnehmen, dass der erste Faktor die Extraversion abbildet und der zweite den Neurotizismus. Als neue Information entnehmen wir der Korrelationsmatrix der Faktoren, welche wir mit <code>$Phi</code> anfordern konnten, dass die beiden Faktoren negativ korreliert sind zu -0.19. Die Frage ist nun, ob unser Modell überhaupt zu den Daten passt.</p>
</div>
<div id="section-exploratische-maximum-likelihood-faktorenanalyse-ml-efa" class="section level3">
<h3>Exploratische Maximum-Likelihood-Faktorenanalyse (ML-EFA)</h3>
<p>Wir möchten unsere Analysen nun gegen andere konkurrierende Modelle absichern sowie untersuchen, ob unser zweifaktorielles Modell überhaupt zu den Daten passt. Hierzu müssen wir annehmen, dass unsere Daten multivariat normalverteilt sind. Wie man diese Annahme zumindest deskriptiv untersucht, hatten wir im Zusammenhang mit den Voraussetzungen von statistischen Verfahren kennengelernt (Mahalanobisdistanz sollte approximativ <span class="math inline">\(\chi^2\)</span>-verteilt sein, siehe hierzu im <strong>Appendix A</strong> nach). Mit Hilfe dieser Verteilungsannahme können wir die Maximum-Likelihood-Schätzmethode nutzen, um die Parameter in unserem Modell zu schätzen. Die <em>Likelihood</em> ist die Wahrscheinlichkeit unserer Daten gegeben das Modell. Sie hängt somit von den beobachteten Daten ab (den Ausprägungen der Personen auf den Variablen), hat die Gestalt unseres Modells (<em>hier</em>: Faktorsstruktur mit normalverteilten Faktoren und Fehlern) und wird parametrisiert durch die Koeffizienten (Parameter) in unserem Modell (<em>hier</em>: <span class="math inline">\(\lambda_{..}\)</span> und <span class="math inline">\(\theta_{..}\)</span> im unkorrelierten Modell vor Rotation). Die durch das Modell implizierte Kovarianz oder Korrelationsmatrix wird mit <span class="math inline">\(\Sigma\)</span> betitelt und setzt sich folgendermaßen zusammen:</p>
<p><span class="math display">\[\Sigma := \Lambda \Lambda&#39; + \Theta.\]</span></p>
<p>Da die Normalveteilung bereits durch die Kovarianzmatrix sowie die Mittelwerte eindeutig zu bestimmen ist, reicht es die Kovarianzmatrix mit Hilfe unserer Modellparameter so anzupassen, dass sie möglichst nah an der Kovarianzmatrix der Daten liegt; die Likelihood ist hier dann maximal. Die Parameter, die die Likelihood maximieren, werden Maxmimum-Liklihood-Schätzer genannt. Sie sind die Schätzung der Parameter, die am wahrscheinlichsten eine solche Datenkonstellation hervorrufen; gegeben das Modell.</p>
<p>Um mit Hilfe von <code>fa</code> eine ML-EFA durchzuführen, muss dem Argument <code>fm</code> die entsprechende Bezeichnung <code>&quot;ml&quot;</code> übergeben werden. <code>$STATISTIC</code> und <code>$PVAL</code> entlocken der Analyse (abgespeichert als Objekt) den <span class="math inline">\(\chi^2\)</span> Wert und den zugehörigen p-Wert bei 4 Freiheitsgraden.</p>
<pre class="r"><code>### ML
two_factor_ML &lt;- fa(dataFR2, nfactors = 2, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
two_factor_ML</code></pre>
<pre><code>## Factor Analysis using method =  ml
## Call: fa(r = dataFR2, nfactors = 2, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
## Standardized loadings (pattern matrix) based upon correlation matrix
##      ML1   ML2   h2   u2 com
## E1  0.69  0.04 0.47 0.53 1.0
## E2 -0.65 -0.06 0.41 0.59 1.0
## E3  0.83 -0.06 0.71 0.29 1.0
## N1  0.03  0.84 0.70 0.30 1.0
## N2  0.10 -0.57 0.35 0.65 1.1
## N3 -0.01  0.59 0.36 0.64 1.0
## 
##                        ML1  ML2
## SS loadings           1.61 1.39
## Proportion Var        0.27 0.23
## Cumulative Var        0.27 0.50
## Proportion Explained  0.54 0.46
## Cumulative Proportion 0.54 1.00
## 
##  With factor correlations of 
##       ML1   ML2
## ML1  1.00 -0.18
## ML2 -0.18  1.00
## 
## Mean item complexity =  1
## Test of the hypothesis that 2 factors are sufficient.
## 
## The degrees of freedom for the null model are  15  and the objective function was  1.47 with Chi Square of  183.82
## The degrees of freedom for the model are 4  and the objective function was  0.07 
## 
## The root mean square of the residuals (RMSR) is  0.04 
## The df corrected root mean square of the residuals is  0.07 
## 
## The harmonic number of observations is  129 with the empirical chi square  5.6  with prob &lt;  0.23 
## The total number of observations was  129  with Likelihood Chi Square =  8.75  with prob &lt;  0.068 
## 
## Tucker Lewis Index of factoring reliability =  0.893
## RMSEA index =  0.099  and the 90 % confidence intervals are  0 0.184
## BIC =  -10.69
## Fit based upon off diagonal values = 0.99
## Measures of factor score adequacy             
##                                                    ML1  ML2
## Correlation of (regression) scores with factors   0.90 0.88
## Multiple R square of scores with factors          0.80 0.77
## Minimum correlation of possible factor scores     0.61 0.55</code></pre>
<p>Wir sehen, dass diesmal die Schätzmethode “ml” ist. Auch die Faktoren heißen nun <em>ML1</em> und <em>ML2</em>. Die Faktorladungen im ML-EFA Modell mit <em>obliquer</em> Rotation sehen den Faktorladungen aus unserer zuvorigen Analyse sehr ähnlich. Uns interessiert nun die Modellpassung. Der <code>Likelihood Chi Square</code> ist der richtige. Diesen entlocken wir nun dem <code>two_factor_ML</code> Objekt:</p>
<pre class="r"><code>two_factor_ML$STATISTIC # Likelihood basierter Chi^2-Wert</code></pre>
<pre><code>## [1] 8.749298</code></pre>
<pre class="r"><code>two_factor_ML$PVAL # p-Wert</code></pre>
<pre><code>## [1] 0.06768059</code></pre>
<p>Dem ist zu entnehmen, dass auf dem Signifikanzniveau von 5% die Hypothese auf Passung der Kovarianz unserer Daten mit der modellimplizierten Kovarianz in der Population nicht verworfen wird. Die Daten widersprechen dem zweifaktoriellen Modell nicht. Vielleicht reicht auch ein Faktor aus, um die Variation in unserem Datensatz zu beschreiben? Wir wollen unser Modell mit zwei Faktoren gegen eines mit einem und eines mit drei Faktoren absichern.</p>
</div>
<div id="section-modellvergleich-ml-efa" class="section level3">
<h3>Modellvergleich: ML-EFA</h3>
<pre class="r"><code># Passt auch eines mit 1 Faktor?
one_factor_ML &lt;- fa(dataFR2, nfactors = 1, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
one_factor_ML$chi # Chi-Quadratwert </code></pre>
<pre><code>## [1] 142.428</code></pre>
<pre class="r"><code>one_factor_ML$PVAL # p-Wert</code></pre>
<pre><code>## [1] 7.063217e-13</code></pre>
<p>Das einfaktorielle Modell scheint nicht zu den Daten zu passen (<em>Mit einer Irrtumswahrscheinlichkeit von 5% ist davon auszugehen, dass in der Population die Differenz zwischen der Populationskovarianzmatrix und der modellimplizierten Kovarianzmatrix nicht 0 ist.</em>). Dennoch wollen wir dies genau wissen und testen mit die beiden geschachtelten (die Modell lassen sich auseinander gewinnen: das zweifaktorielle Modell lässt sich aus dem restrikiveren, einfaktoriellen Modell durch freisetzen der Faktorladungen auf dem 2. Faktor sowie durch Freisetzung der Kovarianz zwischen den Faktoren gewinnen).</p>
<p>Mit Hilfe des <code>anova</code> Befehls, welchen wir schon aus einigen anderen Modellvergleichen im Rahmen der Regression, der logistischen Regression sowie der Multi-Level Modelle kennengelernt haben, lässt sich nun das einfaktorielle mit dem zweifaktoriellen Modell vergleichen.</p>
<pre class="r"><code>anova(one_factor_ML, two_factor_ML) # 2 Faktoren passen besser zu den Daten!</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Model Df"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["ML Chisq"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Delta Df"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["Delta Chisq"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Pr(> Delta Chisq)"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["Emp Chisq"],"name":[6],"type":["dbl"],"align":["right"]},{"label":[" Delta Emp Chisq"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["Pr(> Emp.Delta Chisq)"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["BIC"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["Delta BIC"],"name":[10],"type":["dbl"],"align":["right"]}],"data":[{"1":"9","2":"76.769354","3":"NA","4":"NA","5":"NA","6":"142.427962","7":"NA","8":"NA","9":"33.03104","10":"NA","_rn_":"one_factor_ML"},{"1":"4","2":"8.749298","3":"5","4":"68.02006","5":"2.644945e-13","6":"5.602136","7":"136.8258","8":"8.456822e-28","9":"-10.68995","10":"-43.72099","_rn_":"two_factor_ML"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Im Output des <code>anova</code> Befehls müssen wir im Bereich des <em>Chisq-Tests</em> und nicht beim <em>Emp Chisq</em> (eine Nährung des <span class="math inline">\(\chi^2\)</span> Wertes, wenn Annahmen verletzt sind) nachsehen. Der <span class="math inline">\(\chi^2\)</span>-Differenzwert liegt bei 68.02 mit einen zugehörigen p-Wert von de facto 0 (<code>e-13</code> bedeutet <span class="math inline">\(*10^{-13}\)</span>; also eine Zahl, bei welcher die Dezimalstelle um 13 Stellen nach links verschoben wird - eine sehr kleine Zahl!). <em>Delta Df</em> (häufig <span class="math inline">\(\Delta df\)</span>) gibt die Anzahl an Freiheitsgraden an (hier: df = 5). Somit wird die Null-Hypothese, dass beide Modell die Daten gleich gut beschreiben verworfen. Wir entscheiden uns somit für das Modell mit mehr Parametern, das weniger restriktive Modell, welches die Daten besser beschreibt: hier das zweifaktorielle Modell. Nun ist die Frage, ob wir das Modell noch weiter verbessern können, indem wir drei anstatt zwei Faktoren verwenden, um die Kovariation zwischen den Variablen zu beschreiben.</p>
<pre class="r"><code># Passt auch eines mit 3 Faktor?
three_factor_ML &lt;- fa(dataFR2, nfactors = 3, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
three_factor_ML$chi # der Chi-Quadratwert ist de facto 0</code></pre>
<pre><code>## [1] 0.02121607</code></pre>
<pre class="r"><code>three_factor_ML$PVAL # p-Wert</code></pre>
<pre><code>## [1] NA</code></pre>
<p>Das dreifaktorielle Modell beschreibt die Daten perfekt. Das liegt daran, dass es im dreifaktoriellen Modell genauso viele Parameter gibt, wie es empirische Informationen im Datensatz gibt. Demnach lässt sich die empirische Korrelationsmatrix perfekt durch die modelltheoretische Korrelationsmatrix (diejenige Korrelationsmatrix, die sich ergibt, wenn nur die Beziehungen zwischen den Variablen bestehen, die durch das Modell angenommen werden) darstellen. Ein Test auf Modellpassung ist in diesem Fall nicht möglich und auch nicht nötig (deshalb wird beim <code>$PVAL</code> nichts bzw. <code>NA</code> ausgegeben). Nun vergleichen wir die beiden Modelle:</p>
<pre class="r"><code>anova(two_factor_ML, three_factor_ML) # kein Unterschied zwischen 2 und 3 Faktoren</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Model Df"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["ML Chisq"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Delta Df"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["Delta Chisq"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Pr(> Delta Chisq)"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["Emp Chisq"],"name":[6],"type":["dbl"],"align":["right"]},{"label":[" Delta Emp Chisq"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["Pr(> Emp.Delta Chisq)"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["BIC"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["Delta BIC"],"name":[10],"type":["dbl"],"align":["right"]}],"data":[{"1":"4","2":"8.7492981","3":"NA","4":"NA","5":"NA","6":"5.60213625","7":"NA","8":"NA","9":"-10.68995","10":"NA","_rn_":"two_factor_ML"},{"1":"0","2":"0.0328432","3":"4","4":"8.716455","5":"0.06859098","6":"0.02121607","7":"5.58092","8":"0.2327076","9":"-10.68995","10":"NA","_rn_":"three_factor_ML"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Der <span class="math inline">\(\chi^2\)</span>-Differenzwert liegt hier bei 8.716 mit einen zugehörigen p-Wert von 0.069. <em>Delta Df</em> liegt bei 4 (<span class="math inline">\(\Delta df\)</span> = 4). Somit wird die Null-Hypothese, dass beide Modell die Daten gleich gut beschreiben nicht verworfen. Aus diesem Grund entscheiden wir uns für das sparsamere Modell, also jenes, welches weniger Parameter enthält und somit restriktiver ist, hier: das zweifaktorielle Modell.</p>
</div>
</div>
<div id="section-ml-efa-für-den-gesamten-gekürtzten-datensatz" class="section level2">
<h2>ML-EFA für den gesamten (gekürtzten) Datensatz</h2>
<p>Für den vollen Datensatz mit jeweils drei Items pro Persönlichkeitsfacette, nehmen wir zunächst an, dass es 5 Faktoren gibt. Dies wird hier allerdings nicht durch die Parallelanalyse gestüzt. Wir müssen die Funktion <code>fa.parallel</code> diesmal auf den vollen (gekürtzten) Datensatz anwenden; namlich auf <code>dataFR</code>.</p>
<pre class="r"><code>fa.parallel(x = dataFR)</code></pre>
<p><img src="EFA_files/figure-html/unnamed-chunk-20-1.png" width="624" /></p>
<pre><code>## Parallel analysis suggests that the number of factors =  4  and the number of components =  4</code></pre>
<p>Hier scheinen eher 4 Faktoren sinnvoll. Wir prüfen dennoch erstmal unsere inhaltliche Hypothese, dass es 5 Faktoren gibt, mit Hilfe der <em>oblique</em> Rotierten ML-EFA.</p>
<pre class="r"><code>### ML
five_factor_ML &lt;- fa(dataFR, nfactors = 5, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
five_factor_ML$STATISTIC</code></pre>
<pre><code>## [1] 44.07717</code></pre>
<pre class="r"><code>five_factor_ML$PVAL # Modell wird durch die Daten nicht verworfen</code></pre>
<pre><code>## [1] 0.3031972</code></pre>
<p>Die Daten scheinen unserem Modell mit 5 Faktoren nicht zu wiedersprechen. Schauen wir uns die Faktorladungen an, um die Faktoren inhaltlich zu interpretieren.</p>
<pre class="r"><code>five_factor_ML$loadings</code></pre>
<pre><code>## 
## Loadings:
##    ML4    ML3    ML1    ML2    ML5   
## E1  0.688                            
## E2 -0.643         0.155              
## E3  0.813         0.117              
## N1         0.433 -0.340              
## N2                0.986              
## N3         0.920                     
## A1 -0.227  0.160  0.203        -0.276
## A2  0.655  0.242                     
## A3 -0.186  0.159         0.197       
## C1         0.170  0.208  0.179 -0.355
## C2                              0.730
## C3         0.177  0.140  0.145 -0.278
## O1                       0.998       
## O2  0.126  0.247        -0.214 -0.106
## O3         0.229  0.163  0.189       
## 
##                  ML4   ML3   ML1   ML2   ML5
## SS loadings    2.091 1.328 1.274 1.194 0.869
## Proportion Var 0.139 0.089 0.085 0.080 0.058
## Cumulative Var 0.139 0.228 0.313 0.392 0.450</code></pre>
<p>Durch die Rotation sind auch hier die Faktoren anders nummeriert. Der erste Faktor ist hier <em>ML4</em> (dieser Faktor ist der erste in der Liste, da hier der Eigenwerte nach Rotation maximal ist; vor Rotation hatte <em>ML4</em> den viert größten Eigenwert). Die höchsten Faktorladungen mit diesem Faktor haben die Items <span class="math inline">\(E_1\)</span>, <span class="math inline">\(E_2\)</span>, <span class="math inline">\(E_3\)</span> und <span class="math inline">\(A_2\)</span>. Somit könnte man diesen am ehesten als Extraversion interpretieren. Allerdings scheinen die Items der Extraversion einiges mit jenen der Verträglichkeit (<span class="math inline">\(A_{...}\)</span>) gemeinsam zu haben. <mark style="background-color: orange"> Dies könnte mit unter damit zusammen hängen, dass diese beiden Items am ehesten etwas mit sozialer Erwünschtheit zu tun haben. </mark> Auf dem Faktor <em>ML3</em> laden vor allem die Items <span class="math inline">\(N_1\)</span> und <span class="math inline">\(N_3\)</span>. Allerdings lädt <span class="math inline">\(N_2\)</span> besonders auf <em>ML1</em>.<br />
<mark style="background-color: orange"> Dies könnte durchaus daran liegen, dass <span class="math inline">\(N_1\)</span> (<em>“I get stressed out easily.”</em>) und <span class="math inline">\(N_3\)</span> (<em>“I worry about things.”</em>) negativ kodiert sind, während <span class="math inline">\(N_2\)</span> (<em>“I am relaxed most of the time.”</em>) positiv kodiert ist. Somit scheint <em>ML3</em> ein Faktor der Sorgen, also des Neurotizismus zu sein, während <em>ML1</em> eher für einen Faktor der Gelassenheit spricht; beispielsweise laden hier auch positiv Items der Extraversion und Verträglichkeit.</mark> Auch auf <em>ML2</em> und <em>ML5</em> laden jeweils nur ein Item besonders stark: <span class="math inline">\(O_1\)</span> auf <em>ML2</em> und <span class="math inline">\(C_2\)</span> auf <em>ML5</em>. Insgesamt muss geschlussfolgert werden, dass zwar die fünffaktorielle Struktur durch die Daten nicht verworfen wird, aber dass die oblique rotierte Lösung keine eindeutige Zuordnung der Items aufweist. Allerdings bringt auch eine <em>varimax</em>-rotierte Lösung keine Verbesserung der Interpretierbarkeit:</p>
<pre class="r"><code>fa(dataFR, nfactors = 5, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)$loadings</code></pre>
<pre><code>## 
## Loadings:
##    ML4    ML3    ML1    ML2    ML5   
## E1  0.688                            
## E2 -0.643         0.155              
## E3  0.813         0.117              
## N1         0.433 -0.340              
## N2                0.986              
## N3         0.920                     
## A1 -0.227  0.160  0.203        -0.276
## A2  0.655  0.242                     
## A3 -0.186  0.159         0.197       
## C1         0.170  0.208  0.179 -0.355
## C2                              0.730
## C3         0.177  0.140  0.145 -0.278
## O1                       0.998       
## O2  0.126  0.247        -0.214 -0.106
## O3         0.229  0.163  0.189       
## 
##                  ML4   ML3   ML1   ML2   ML5
## SS loadings    2.091 1.328 1.274 1.194 0.869
## Proportion Var 0.139 0.089 0.085 0.080 0.058
## Cumulative Var 0.139 0.228 0.313 0.392 0.450</code></pre>
<div id="section-modellvergleich-ml-efa-1" class="section level3">
<h3>Modellvergleich: ML-EFA</h3>
<p>Wir schauen uns nun die Passung unseres Modells im Vergleich zu einem vier- und einem sechsfaktoriellen Modell an.</p>
<pre class="r"><code># Passt auch eines mit 4 Faktor auch?
four_factor_ML &lt;- fa(dataFR, nfactors = 4, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
four_factor_ML$chi #  Chi-Quadratwert </code></pre>
<pre><code>## [1] 105.8101</code></pre>
<pre class="r"><code>four_factor_ML$PVAL # p-Wert</code></pre>
<pre><code>## [1] 0.023097</code></pre>
<p>Das vierfaktorielle Modell wird durch die Daten verworfen (<span class="math inline">\(p&lt;0.05\)</span>). Auch der Modellvergleich</p>
<pre class="r"><code>anova(four_factor_ML, five_factor_ML) # sig</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Model Df"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["ML Chisq"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Delta Df"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["Delta Chisq"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Pr(> Delta Chisq)"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["Emp Chisq"],"name":[6],"type":["dbl"],"align":["right"]},{"label":[" Delta Emp Chisq"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["Pr(> Emp.Delta Chisq)"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["BIC"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["Delta BIC"],"name":[10],"type":["dbl"],"align":["right"]}],"data":[{"1":"51","2":"73.04596","3":"NA","4":"NA","5":"NA","6":"105.81010","7":"NA","8":"NA","9":"-174.8045","10":"NA","_rn_":"four_factor_ML"},{"1":"40","2":"44.07717","3":"11","4":"28.96878","5":"0.002295412","6":"47.93547","7":"57.87463","8":"2.295132e-08","9":"-150.3153","10":"24.48915","_rn_":"five_factor_ML"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>zeigt, dass die beiden Modell nicht gleich gut zu den Daten passen <span class="math inline">\(p&lt;0.01\)</span>. Damit entscheiden wir uns für das komplexere Modell mit mehr Parametern (und somit mehr Faktoren): das fünffaktorielle Modell.</p>
<pre class="r"><code># Passt auch eines mit 6 Faktor?
six_factor_ML &lt;- fa(dataFR, nfactors = 6, rotate = &quot;oblimin&quot;, fm = &quot;ml&quot;)
six_factor_ML$chi #  Chi-Quadratwert </code></pre>
<pre><code>## [1] 28.62638</code></pre>
<pre class="r"><code>six_factor_ML$PVAL # p-Wert </code></pre>
<pre><code>## [1] 0.5074152</code></pre>
<p>Dem sechsfaktoriellen Modell widersprechen die Daten genauso wenig, wie dem Fünffakoriellen (beide <span class="math inline">\(p&gt;0.05\)</span>). <mark style="background-color: orange"> Dies war zu erwarten, da wir durch Hinzunahme des sechsten Faktors die Komplexität das Modell erhöht haben, was den Modellfit nur verbessern kann. </mark></p>
<pre class="r"><code>anova(five_factor_ML, six_factor_ML) # n.s.</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Model Df"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["ML Chisq"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Delta Df"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["Delta Chisq"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Pr(> Delta Chisq)"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["Emp Chisq"],"name":[6],"type":["dbl"],"align":["right"]},{"label":[" Delta Emp Chisq"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["Pr(> Emp.Delta Chisq)"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["BIC"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["Delta BIC"],"name":[10],"type":["dbl"],"align":["right"]}],"data":[{"1":"40","2":"44.07717","3":"NA","4":"NA","5":"NA","6":"47.93547","7":"NA","8":"NA","9":"-150.3153","10":"NA","_rn_":"five_factor_ML"},{"1":"30","2":"29.19415","3":"10","4":"14.88302","5":"0.1363852","6":"28.62638","7":"19.30909","8":"0.03650793","9":"-116.6002","10":"33.7151","_rn_":"six_factor_ML"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Der <span class="math inline">\(\chi^2\)</span>-Differenzwert liegt hier bei 14.883 mit einen zugehörigen p-Wert 0.1364 mit <span class="math inline">\(\Delta df\)</span> = 10. <mark style="background-color: orange">Somit wird die Null-Hypothese, dass beide Modell die Daten gleich gut beschreiben, auf dem 5%-Niveau nicht verworfen. Wir entscheiden uns nach dem Sparsamkeitsprinzip für das Modell mit weniger Parametern, also für das restriktive Modell mit fünf Faktoren, welches die Daten nicht signifikant schlechter beschreibt, als das komplexere mit sechs Faktoren. <em>In der Regel sind Modelle mit weniger Parametern leichter zu interpretieren.</em> </mark></p>
<p><mark style="background-color: orange">Da die Zuordnung zwischen Faktoren und Items nicht eindeutig zu interpretieren war, müsste dies in Zukunft weiter untersucht werden. Weitere geziehlte Hypothesen lassen sich beispielsweise mit der <strong>konfirmatorischen Faktoren Analyse (CFA; confirmatory factor analysis)</strong> untersuchen. </mark></p>
</div>
</div>
<div id="section-appendix" class="section level2">
<h2>Appendix</h2>
</div>
<div id="section-appendix-a-prüfen-der-voraussetzungen" class="section level2">
<h2><strong>Appendix A:</strong> Prüfen der Voraussetzungen</h2>
<p>Auf multivariate Normalverteilung können wir beispeilsweise <strong>deskriptiv</strong> prüfen, indem wir die Mahalanobisdistanz (die Distanz vom gemeinsame Zentroiden; dem Mittelwert über alle Variablen; unter Berücksichtigung der Kovariation im Datensatz) plotten und sie mit einer <span class="math inline">\(\chi^2\)</span>-Verteilung vergleichen; wobei <span class="math inline">\(df=p\)</span> und <span class="math inline">\(p=\)</span> Anzahl an Variablen (hier <span class="math inline">\(df=p=15\)</span>).</p>
<pre class="r"><code>Mahalanobis_Distanz &lt;- mahalanobis(x = dataFR, cov = cov(dataFR), center = apply(X = dataFR, MARGIN = 2, FUN = mean)) # Berechnen der Mahalanobisdistanz
hist(Mahalanobis_Distanz, col = &quot;skyblue&quot;, border = &quot;blue&quot;, freq = F, breaks = 15) # Histogramm
lines(x = seq(0, max(Mahalanobis_Distanz), 0.01), y = dchisq(x = seq(0, max(Mahalanobis_Distanz), 0.01), df = 15), col = &quot;darkblue&quot;, lwd = 4) # Einzeichnen der Dichte</code></pre>
<p><img src="EFA_files/figure-html/unnamed-chunk-28-1.png" width="624" /></p>
<p>Das Histogramm scheint nicht perfekt zur <span class="math inline">\(\chi^2\)</span> Verteilung zu passen. Allerdings sind die Abweichungen auch nicht enorm. <mark style="background-color: orange">Wir verwerfen auf Basis des Histogramms die Normalverteilungsannahme nicht, sollten die Ergebnisse aber trotzdem unter Vorbehalt interpretiert werden. </mark></p>
<p>Die Funktion <code>mahalanobis</code> berechnet die Mahalanobisdistanz pro Proband. Als Datenargument braucht sie eine Matrix <code>x</code>. Die Mahalanobisdistanz ist ein Distanzmaß, welches die korrelative Struktur in den Daten berücksichtig. Wir übergeben daher mit <code>cov = cov(dataFR)</code> der Funktion <code>mahalanobis</code> die empirische Kovarianzmatrix unserer Daten (<code>cov(dataFR)</code>), um diese Struktur mit zuberücksichtigen. Außerdem müssen die Variablen und deren Variation relativ zu einem Zentroiden angegeben werden. Der Zentroid kann dem <code>center</code> Argument übergeben werden. Wir brauchen also für jede Variable den Mittelwert. Dies berechnen wir mit <code>mean</code> und der <code>apply</code>-Funktion (Man könnte dies natürlich auch “zu Fuß” für jede Variable einzeln machen, die Mittelwert in einem Vektor abspeichern und diesen hier angeben). Die Funktion <code>apply</code> führt auf die Datenmatrix, welche dem Argument <code>X</code> übergeben wird, entweder über die Zeilen <code>MARGIN = 1</code> oder über die Spalten <code>MARGIN = 2</code> (hier gewählt) die Funktion aus, welche im Argument <code>FUN</code> angegeben wird. So wird mit <code>FUN = mean</code> der Mittelwert über alle Variablen in <em>dataFR</em> berechnet.</p>
<pre class="r"><code>apply(X = dataFR, MARGIN = 2, FUN = mean)</code></pre>
<pre><code>##       E1       E2       E3       N1       N2       N3       A1       A2 
## 2.558140 2.968992 3.217054 3.372093 3.131783 3.852713 2.620155 3.596899 
##       A3       C1       C2       C3       O1       O2       O3 
## 2.286822 3.100775 3.131783 4.000000 3.945736 2.077519 4.240310</code></pre>
<p>Der <code>hist</code> Befehl erzeugt schließlich ein Histogramm der Mahalanobisdistanzen. Mit den Argumenten <code>col = &quot;skyblue&quot;</code> und <code>border = &quot;blue&quot;</code> setzten wir die Farben des Histogramms fest. Mit <code>freq = F</code> sagen wir, dass wir nicht die absoluten sondern die relativen Häufigkeiten angezeigt haben wollen (dies brauchen wir um anschließend die Dichte der <span class="math inline">\(\chi^2\)</span>-Verteilung einzuzeichnen). Mit <code>breaks = 15</code> beschließen wir, dass insgesamt ca. 15 Balken gezeichnet werden sollen.</p>
<p>Schließlich zeichnen wir mit <code>lines</code> eine Line, welche als x-Argument <code>x = seq(0, max(Mahalanobis_Distanz), 0.01)</code> eine Sequenz von Zahlen von 0 bis zur maximalen Mahalanobisdistanz erhält und in 0.01 Schritten wächst. Gegen diese x-Werte zeichnen wir die Dichte der <span class="math inline">\(\chi^2(df=15)\)</span>-Verteilung ein: <code>y = dchisq(x = seq(0, max(Mahalanobis_Distanz), 0.01), df = 15)</code>. <code>col = &quot;darkblue&quot;</code> und <code>lwd = 4</code> setzten jeweils die Linienfarbe und Liniendicke fest. Weitere Informationen zu Verteilungen und wie man diese in <code>R</code> umsetzt, können im <a href="https://en.wikibooks.org/wiki/R_Programming/Probability_Distributions">R-Wiki zu Verteilungen</a>, in <a href="https://de.wikipedia.org/wiki/Wahrscheinlichkeitsdichtefunktion">Wikipedia zu Verteilungen und Dichten</a> oder in einer <a href="https://www.statmethods.net/advgraphs/probability.html">Kurzzusammenfassung auf statethods</a> nachgelesen werden. Grundlagen hierzu können außerdem in Eid et al. (2017) in Kapitel 7 ab Seite 171 gefunden werden.</p>
</div>
<div id="section-literatur" class="section level2">
<h2>Literatur</h2>
<p><a href="https://hds.hebis.de/ubffm/Record/HEB366849158">Eid, M., Gollwitzer, M., &amp; Schmitt, M. (2017).</a> <em>Statistik und Forschungsmethoden</em> (5. Auflage, 1. Auflage: 2010). Weinheim: Beltz.</p>
<ul>
<li><small> <em>Blau hinterlegte Autorenangaben führen Sie direkt zur universitätsinternen Ressource.</em> 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = NULL)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
session$onSessionEnded(function() {
        learnr:::session_stop_event(session)
      })
</script>
 
<script type="application/shiny-prerendered" data-context="data">
# Datensatz laden 
load("Big5.rda") # shortend Big 5 Questionnaire Data Set
head(Big5, n = 10) # gebe die ersten 10 Zeilen aus
</script>
 <!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["navigation"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/navigation-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tabsets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["default.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["5.1.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.css","css/v4-shims.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["4.4.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["idb-keyvalue"]},{"type":"character","attributes":{},"value":["3.2.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/idb-keyval"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["idb-keyval-iife-compat.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50]}},"value":[{"type":"character","attributes":{},"value":["backports","base","checkmate","compiler","corrplot","datasets","digest","evaluate","fastmap","fontawesome","foreign","GPArotation","gradethis","graphics","grDevices","grid","htmlTable","htmltools","htmlwidgets","httpuv","jsonlite","knitr","later","lattice","learnr","magrittr","markdown","methods","mime","mnormt","nlme","parallel","promises","psych","R6","Rcpp","rlang","rmarkdown","rprojroot","rstudioapi","shiny","stats","stringi","stringr","tools","utils","withr","xfun","xtable","yaml"]},{"type":"character","attributes":{},"value":["1.1.5","3.6.3","2.0.0","3.6.3","0.84","3.6.3","0.6.25","0.14","1.0.1","0.1.0","0.8-75","2014.11-1","0.1.0.9002","3.6.3","3.6.3","3.6.3","1.13.3","0.4.0","1.5.1","1.5.2","1.6","1.25","1.0.0","0.20-38","0.10.1","1.5","1.1","3.6.3","0.7","1.5-5","3.1-144","3.6.3","1.1.0","1.8.12","2.4.1","1.0.4","0.4.5","1.16","1.3-2","0.10","1.4.0","3.6.3","1.4.3","1.4.0","3.6.3","3.6.3","2.1.2","0.10","1.8-4","2.2.0"]}]}]}
</script>
<!--/html_preserve--></li>
</ul>
</div>

</div> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h2 class="title toc-ignore" style="display:none;">Sitzung 2: Exploratorische Faktorenanalyse</h2>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</div> <!-- bandContent page -->
</div> <!-- pageContent band -->


<hr />
<!-- Add icon library -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<p style="text-align: center;">Julien P. Irmer & Martin Schultze</p>
<p style="text-align: center;">PsyMSc1 Seminar, SoSe 2020</p>
<p style="text-align: center;">
    <a title="OLAT" href="https://olat-ce.server.uni-frankfurt.de/olat/auth/RepositoryEntry/8136491044" class="fa fa-link"></a>
    <a title="GitHub" href="https://github.com/martscht/PsyMSc1" class="fa fa-github"></a>
    <a title="Lizenz" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" class="fab fa-creative-commons"></a>
</p>


<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>

</html>
